{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "%matplotlib inline\n",
    "%load_ext Cython\n",
    "\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_path=\"/kaggle/input/recommender-system-2023-challenge-polimi/data_train.csv\"\n",
    "# data_target_user_path=\"/kaggle/input/recommender-system-2023-challenge-polimi/data_target_users_test.csv\"\n",
    "data_train_path=\"data_train.csv\"\n",
    "data_target_user_path=\"data_target_users_test.csv\"\n",
    "data_train = pd.read_csv(data_train_path)\n",
    "data_target = pd.read_csv(data_target_user_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13024x22222 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 478730 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all =  data_train.pivot(index='row', columns='col', values='data').fillna(0)\n",
    "item_map = {i : item for i, item in enumerate(URM_all.columns)}\n",
    "user_map = {i : user for i, user in enumerate(data_target[\"user_id\"])}\n",
    "item_map_inv = {item : i for i, item in item_map.items()}\n",
    "user_map_inv = {user : i for i, user in user_map.items()}\n",
    "missing_index = [x for x in range(1,13025) if x not in URM_all.index.tolist()]\n",
    "add_urm = pd.DataFrame(index = missing_index, columns = URM_all.columns).fillna(0)\n",
    "URM_all = pd.concat([URM_all, add_urm]).sort_index()\n",
    "del add_urm\n",
    "del missing_index\n",
    "#data_target[\"user_id\"] = data_target[\"user_id\"]\n",
    "URM_all = URM_all.to_numpy()\n",
    "URM_all = sps.csr_matrix(URM_all)\n",
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 603 (4.63 %) of 13024 users have no train items\n",
      "Warning: 2521 (19.36 %) of 13024 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "URM_train, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)\n",
    "n_users, n_items = URM_train.shape\n",
    "# evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from libc.stdlib cimport rand, srand, RAND_MAX\n",
    "\n",
    "def train_multiple_epochs(URM_train, learning_rate_input, regularization_2_input, n_epochs):\n",
    "\n",
    "    URM_train_coo = URM_train.tocoo()\n",
    "    cdef int n_items = URM_train.shape[1]\n",
    "    cdef int n_interactions = URM_train.nnz\n",
    "    cdef int[:] URM_train_coo_row = URM_train_coo.row\n",
    "    cdef int[:] URM_train_coo_col = URM_train_coo.col\n",
    "    cdef double[:] URM_train_coo_data = URM_train_coo.data\n",
    "    cdef int[:] URM_train_indices = URM_train.indices\n",
    "    cdef int[:] URM_train_indptr = URM_train.indptr\n",
    "    cdef double[:] URM_train_data = URM_train.data\n",
    "\n",
    "    cdef double[:,:] item_item_S = np.zeros((n_items, n_items), dtype = float)\n",
    "    cdef double learning_rate = learning_rate_input\n",
    "    cdef double regularization_2 = regularization_2_input\n",
    "    cdef double loss = 0.0\n",
    "    cdef long start_time\n",
    "    cdef double true_rating, predicted_rating, prediction_error, profile_rating\n",
    "    cdef int start_profile, end_profile\n",
    "    cdef int index, sample_num, user_id, item_id, profile_item_id\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        \n",
    "        loss = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for sample_num in range(n_interactions):\n",
    "\n",
    "            # Randomly pick sample\n",
    "            index = rand() % n_interactions\n",
    "\n",
    "            user_id = URM_train_coo_row[index]\n",
    "            item_id = URM_train_coo_col[index]\n",
    "            true_rating = URM_train_coo_data[index]\n",
    "\n",
    "            # Compute prediction\n",
    "            start_profile = URM_train_indptr[user_id]\n",
    "            end_profile = URM_train_indptr[user_id+1]\n",
    "            predicted_rating = 0.0\n",
    "\n",
    "            for index in range(start_profile, end_profile):\n",
    "                profile_item_id = URM_train_indices[index]\n",
    "                profile_rating = URM_train_data[index]\n",
    "                predicted_rating += item_item_S[profile_item_id,item_id] * profile_rating\n",
    "\n",
    "            # Compute prediction error, or gradient\n",
    "            prediction_error = true_rating - predicted_rating\n",
    "            loss += prediction_error**2\n",
    "\n",
    "            # Update model, in this case the similarity\n",
    "            for index in range(start_profile, end_profile):\n",
    "                profile_item_id = URM_train_indices[index]\n",
    "                profile_rating = URM_train_data[index]\n",
    "                item_item_S[profile_item_id,item_id] += learning_rate * (prediction_error * profile_rating - \n",
    "                                                                         regularization_2 * item_item_S[profile_item_id,item_id])\n",
    "\n",
    "            # Ensure diagonal is always zero\n",
    "            item_item_S[item_id,item_id] = 0.0\n",
    "        \n",
    "#             if sample_num % 1000000 == 0:\n",
    "#                 print(\"Epoch {}: {:.2f}%\".format(n_epoch+1, sample_num/n_interactions*100))\n",
    "            \n",
    "            \n",
    "        elapsed_time = time.time() - start_time\n",
    "        samples_per_second = (sample_num+1)/elapsed_time\n",
    "     \n",
    "        print(\"Epoch {} complete in in {:.2f} seconds, loss is {:.3E}. Samples per second {:.2f}\".format(n_epoch+1, time.time() - start_time, loss/(sample_num+1), samples_per_second))\n",
    "\n",
    "    return np.array(item_item_S), loss/(sample_num+1), samples_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete in in 2.44 seconds, loss is 9.988E-01. Samples per second 157144.04\n",
      "Epoch 2 complete in in 1.79 seconds, loss is 9.964E-01. Samples per second 214497.40\n",
      "Epoch 3 complete in in 2.00 seconds, loss is 9.941E-01. Samples per second 191611.67\n",
      "Epoch 4 complete in in 2.11 seconds, loss is 9.917E-01. Samples per second 181122.86\n",
      "Epoch 5 complete in in 1.22 seconds, loss is 9.894E-01. Samples per second 312849.36\n",
      "Epoch 6 complete in in 1.42 seconds, loss is 9.870E-01. Samples per second 269317.92\n",
      "Epoch 7 complete in in 1.63 seconds, loss is 9.847E-01. Samples per second 235489.60\n",
      "Epoch 8 complete in in 1.82 seconds, loss is 9.823E-01. Samples per second 210473.04\n",
      "Epoch 9 complete in in 1.93 seconds, loss is 9.801E-01. Samples per second 198596.86\n",
      "Epoch 10 complete in in 2.08 seconds, loss is 9.777E-01. Samples per second 184490.32\n"
     ]
    }
   ],
   "source": [
    "n_items = URM_train.shape[1]\n",
    "learning_rate = 1e-6\n",
    "regularization_2 = 1e-3\n",
    "    \n",
    "item_item_S, loss, samples_per_second = train_multiple_epochs(URM_train, learning_rate, regularization_2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22222x22222 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2377751 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_item_S_sparse = sps.csr_matrix(item_item_S)\n",
    "item_item_S_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[0.0106289 , 0.01160036, 0.01072798, ..., 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.        , 0.02337011, 0.01952597, ..., 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.00114513, 0.00080015, 0.00045769, ..., 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         ...,\n",
       "         [0.00045349, 0.00012243, 0.00097181, ..., 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.00715307, 0.00882841, 0.00608888, ..., 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.        , 0.02104363, 0.01509153, ..., 0.        , 0.        ,\n",
       "          0.        ]]),\n",
       " (13024, 22222))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = URM_all.dot(item_item_S_sparse)\n",
    "predicted_ratings = predicted_ratings.multiply(1 - URM_all.todense())\n",
    "predicted_ratings.todense(), predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[    1,     2,     0, ..., 14284, 14285, 11110],\n",
       "        [    1,     2,     3, ..., 14245, 14246,     0],\n",
       "        [    0,     8,     6, ..., 14764, 14765, 11110],\n",
       "        ...,\n",
       "        [  808,  1673,    30, ..., 14787, 14788, 11110],\n",
       "        [    8,     1,    10, ..., 14489, 14490, 11110],\n",
       "        [    1,     3,     2, ..., 14166, 14167,     0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(np.argsort(predicted_ratings.todense(), axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20584114517549096"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(predicted_ratings.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix([[    2,     3,    14, ..., 11123, 11122, 11110],\n",
    "#         [    0,     1,     3, ..., 14357, 14358, 11110],\n",
    "#         [   10,     8,     1, ..., 14780, 14781, 11110],\n",
    "#         ...,\n",
    "#         [  808,  1673,     2, ..., 14797, 14798, 11110],\n",
    "#         [    1,     0,     6, ..., 14538, 14539, 11110],\n",
    "#         [    1,     3,     2, ..., 14213, 14214, 11110]], dtype=int64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
